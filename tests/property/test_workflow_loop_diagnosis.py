"""
è¯Šæ–­è„šæœ¬ï¼šè¿½è¸ªå·¥ä½œæµå¾ªç¯ä½ç½®

ç›®çš„ï¼šæ‰¾å‡ºå·¥ä½œæµåœ¨å“ªä¸ªèŠ‚ç‚¹/æ¡ä»¶ä¸Šå¾ªç¯
"""
import asyncio
import sys
import os
import logging
from datetime import datetime
from unittest.mock import Mock, AsyncMock
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.domain.state_types import GlobalState
from src.domain.models import RetrievedDocument, OutlineStep
from src.domain.task_stack import TaskContext
from src.infrastructure.langgraph_error_handler import ErrorCategory
from src.application.orchestrator import WorkflowOrchestrator

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_mock_llm():
    """åˆ›å»º Mock LLM æœåŠ¡"""
    mock = Mock()
    mock.generate = AsyncMock(return_value={
        "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹",
        "confidence": 0.9,
        "metadata": {"model": "test"}
    })
    mock.agenerate = AsyncMock(return_value={
        "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹",
        "confidence": 0.9,
        "metadata": {"model": "test"}
    })
    mock.structured_generate = AsyncMock(return_value={
        "primary_intent": "explanation",
        "keywords": ["æµ‹è¯•"],
        "search_sources": ["web"],
        "confidence": 0.9,
        "intent_type": "lightweight"
    })
    return mock

def create_mock_retrieval():
    """åˆ›å»º Mock æ£€ç´¢æœåŠ¡ - æ•…æ„è¿”å›ä½è´¨é‡ç»“æœ"""
    mock = Mock()
    
    async def mock_search(query: str, top_k: int = 5, filters: Dict = None) -> List[Dict]:
        # æ•…æ„è¿”å›ä½è´¨é‡ç»“æœï¼ˆçŸ­æ–‡æœ¬ï¼‰æ¥è§¦å‘é‡è¯•
        return [
            {
                "content": "çŸ­å†…å®¹",
                "score": 0.3,  # ä½åˆ†æ•°
                "metadata": {"source": "test", "file_path": "/test/doc1.txt"}
            }
        ]
    
    async def mock_vector_search(query: str, top_k: int = 5, filters: Dict = None) -> List[Dict]:
        return mock_search(query, top_k, filters)
    
    async def mock_keyword_search(query: str, top_k: int = 5, filters: Dict = None) -> List[Dict]:
        return mock_search(query, top_k, filters)
    
    async def mock_retrieve_with_strategy(query: str, strategy: str = "hybrid", top_k: int = 5) -> List[Dict]:
        return mock_search(query, top_k, filters)
    
    mock.search = mock_search
    mock.vector_search = mock_vector_search
    mock.keyword_search = mock_keyword_search
    mock.retrieve_with_strategy = mock_retrieve_with_strategy
    
    return mock

def create_mock_parser():
    """åˆ›å»º Mock è§£ææœåŠ¡"""
    mock = Mock()
    mock.parse_outline = Mock(return_value=[
        {"step_id": 0, "title": "æ­¥éª¤ 1", "description": "ç¬¬ä¸€æ­¥æè¿°"},
        {"step_id": 1, "title": "æ­¥éª¤ 2", "description": "ç¬¬äºŒæ­¥æè¿°"},
    ])
    mock.parse_query = Mock(return_value={
        "primary_intent": "informational",
        "keywords": ["æµ‹è¯•"],
        "search_sources": ["web"],
        "confidence": 0.9,
        "intent_type": "lightweight"
    })
    mock.validate_format = Mock(return_value={"valid": True, "errors": []})
    return mock

def create_mock_summarization():
    """åˆ›å»º Mock æ€»ç»“æœåŠ¡"""
    mock = Mock()
    mock.check_size = Mock(return_value=False)  # æ€»æ˜¯è¿”å› Falseï¼Œè¡¨ç¤ºå†…å®¹åœ¨é™åˆ¶å†…
    mock.summarize = AsyncMock(return_value={"summary": "æµ‹è¯•æ€»ç»“", "confidence": 0.9})
    return mock

def create_test_state() -> GlobalState:
    """åˆ›å»ºæµ‹è¯•çŠ¶æ€"""
    return {
        "user_topic": "æµ‹è¯•ä¸»é¢˜",
        "project_context": "æµ‹è¯•ä¸Šä¸‹æ–‡",
        "outline": [
            {
                "step_id": 0,
                "title": "æ­¥éª¤ 1: ä»‹ç»",
                "description": "ä»‹ç»æµ‹è¯•ä¸»é¢˜çš„èƒŒæ™¯ä¿¡æ¯",
                "status": "pending"
            },
            {
                "step_id": 1,
                "title": "æ­¥éª¤ 2: è¯¦ç»†è¯´æ˜",
                "description": "è¯¦ç»†è¯´æ˜æµ‹è¯•ä¸»é¢˜çš„å„ä¸ªæ–¹é¢",
                "status": "pending"
            },
            {
                "step_id": 2,
                "title": "æ­¥éª¤ 3: æ€»ç»“",
                "description": "æ€»ç»“æµ‹è¯•ä¸»é¢˜çš„å…³é”®ç‚¹",
                "status": "pending"
            }
        ],
        "current_step_index": 0,
        "fragments": [],
        "retrieved_docs": [],
        "director_feedback": None,
        "execution_log": [],
        "session_id": "test_session",
        "user_id": "test_user"
    }

class ExecutionTracer:
    """æ‰§è¡Œè¿½è¸ªå™¨ - è®°å½•æ¯æ¬¡èŠ‚ç‚¹è°ƒç”¨"""
    
    def __init__(self):
        self.call_history = []
        self.step_visits = {}  # è®°å½•æ¯ä¸ªæ­¥éª¤è¢«è®¿é—®çš„æ¬¡æ•°
        self.node_visits = {}  # è®°å½•æ¯ä¸ªèŠ‚ç‚¹è¢«è®¿é—®çš„æ¬¡æ•°
    
    def record(self, node_name: str, state: Dict[str, Any], decision: str = None):
        step_index = state.get("current_step_index", -1)
        timestamp = datetime.now().isoformat()
        
        # è®°å½•èŠ‚ç‚¹è®¿é—®
        if node_name not in self.node_visits:
            self.node_visits[node_name] = 0
        self.node_visits[node_name] += 1
        
        # è®°å½•æ­¥éª¤è®¿é—®
        if step_index not in self.step_visits:
            self.step_visits[step_index] = 0
        self.step_visits[step_index] += 1
        
        # è®°å½•è¯¦ç»†å†å²
        feedback = state.get("director_feedback") or {}
        entry = {
            "timestamp": timestamp,
            "node": node_name,
            "step_index": step_index,
            "decision": decision,
            "retry_count": state.get("retrieval_retry_count", 0),
            "quality_score": feedback.get("metadata", {}).get("quality_score", None) if feedback else None,
            "has_retrieved_docs": len(state.get("retrieved_docs", [])) > 0
        }
        self.call_history.append(entry)
        
        # æ‰“å°è¿½è¸ªä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"[{timestamp}] èŠ‚ç‚¹: {node_name}")
        print(f"  æ­¥éª¤ç´¢å¼•: {step_index}")
        print(f"  é‡è¯•æ¬¡æ•°: {entry['retry_count']}")
        print(f"  è´¨é‡åˆ†æ•°: {entry['quality_score']}")
        print(f"  æœ‰æ£€ç´¢ç»“æœ: {entry['has_retrieved_docs']}")
        if decision:
            print(f"  å†³ç­–: {decision}")
        print(f"  èŠ‚ç‚¹è®¿é—®æ¬¡æ•°: {self.node_visits[node_name]}")
        print(f"  æ­¥éª¤ {step_index} è®¿é—®æ¬¡æ•°: {self.step_visits.get(step_index, 0)}")
        print(f"{'='*60}")
        
        # æ£€æµ‹å¾ªç¯
        if self.step_visits.get(step_index, 0) > 3:
            print(f"\nâš ï¸  è­¦å‘Š: æ­¥éª¤ {step_index} å·²è¢«è®¿é—®è¶…è¿‡ 3 æ¬¡ï¼")
            print(f"    å¯èƒ½å­˜åœ¨å¾ªç¯ï¼")
        
        if self.node_visits.get(node_name, 0) > 10:
            print(f"\nâš ï¸  è­¦å‘Š: èŠ‚ç‚¹ {node_name} å·²è¢«è®¿é—®è¶…è¿‡ 10 æ¬¡ï¼")
            print(f"    å¯èƒ½å­˜åœ¨æ­»å¾ªç¯ï¼")
    
    def summary(self):
        print("\n" + "="*60)
        print("æ‰§è¡Œè¿½è¸ªæ‘˜è¦")
        print("="*60)
        print(f"æ€»èŠ‚ç‚¹è°ƒç”¨æ¬¡æ•°: {len(self.call_history)}")
        print("\nèŠ‚ç‚¹è®¿é—®ç»Ÿè®¡:")
        for node, count in sorted(self.node_visits.items(), key=lambda x: -x[1]):
            print(f"  {node}: {count} æ¬¡")
        print("\næ­¥éª¤è®¿é—®ç»Ÿè®¡:")
        for step, count in sorted(self.step_visits.items(), key=lambda x: -x[0]):
            status = "ğŸ”´ å¾ªç¯" if count > 3 else "âœ“"
            print(f"  æ­¥éª¤ {step}: {count} æ¬¡ {status}")
        print("="*60)

async def trace_workflow_execution():
    """è¿½è¸ªå·¥ä½œæµæ‰§è¡Œ"""
    print("\n" + "="*60)
    print("å¼€å§‹å·¥ä½œæµæ‰§è¡Œè¿½è¸ª")
    print("="*60)
    
    # åˆ›å»º Mock æœåŠ¡
    mock_llm = create_mock_llm()
    mock_retrieval = create_mock_retrieval()
    mock_parser = create_mock_parser()
    mock_summarization = create_mock_summarization()
    
    # åˆ›å»ºè¿½è¸ªå™¨
    tracer = ExecutionTracer()
    
    # åˆ›å»º Orchestrator
    orchestrator = WorkflowOrchestrator(
        llm_service=mock_llm,
        retrieval_service=mock_retrieval,
        parser_service=mock_parser,
        summarization_service=mock_summarization,
        enable_agentic_rag=True,  # å¯ç”¨ Agentic RAG
        enable_dynamic_adjustment=False,
        max_retrieval_retries=3  # å…è®¸æ›´å¤šé‡è¯•ä»¥ä¾¿è§‚å¯Ÿ
    )
    
    # åˆå§‹çŠ¶æ€
    initial_state = create_test_state()
    tracer.record("INITIAL", initial_state)
    
    # è®¾ç½®æ‰§è¡Œè¶…æ—¶
    import signal
    
    def timeout_handler(signum, frame):
        print("\n" + "="*60)
        print("â° æ‰§è¡Œè¶…æ—¶ï¼")
        print("="*60)
        tracer.summary()
        raise asyncio.TimeoutError("æ‰§è¡Œè¶…æ—¶")
    
    # è®¾ç½® 30 ç§’è¶…æ—¶
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(30)
    
    try:
        # æ‰§è¡Œå·¥ä½œæµ
        result = await orchestrator.execute(initial_state)
        
        print("\n" + "="*60)
        print("âœ“ å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        print("="*60)
        
        tracer.summary()
        
        return result
        
    except asyncio.TimeoutError:
        print("\nâš ï¸  å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ï¼")
        tracer.summary()
        raise
        
    except Exception as e:
        print(f"\nâœ— å·¥ä½œæµæ‰§è¡Œå‡ºé”™: {e}")
        tracer.summary()
        raise
        
    finally:
        signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

if __name__ == "__main__":
    asyncio.run(trace_workflow_execution())
