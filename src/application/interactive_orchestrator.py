"""äº¤äº’å¼å·¥ä½œæµç¼–æ’å™¨ - æ”¯æŒ Function Calling å’Œç”¨æˆ·å¹²é¢„"""

import logging
from typing import Dict, Any, Optional, List
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from ..domain.state_types import GlobalState
from ..domain.tools.tool_service import ToolService
from ..domain.tools.tool_executor import ToolExecutor
from ..domain.agents.editor_agent import EditorAgent
from ..domain.agents.node_factory import NodeFactory
from .base_orchestrator import BaseWorkflowOrchestrator

logger = logging.getLogger(__name__)


class InteractiveWorkflowOrchestrator(BaseWorkflowOrchestrator):
    """
    äº¤äº’å¼å·¥ä½œæµç¼–æ’å™¨ - æ”¯æŒ Function Calling å’Œç”¨æˆ·å¹²é¢„
    
    ç»§æ‰¿è‡ª BaseWorkflowOrchestratorï¼Œä½¿ç”¨å…±äº«çš„èŠ‚ç‚¹å®ç°ã€‚
    æ‰©å±•åŠŸèƒ½ï¼š
    1. Editor Agent èŠ‚ç‚¹ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å’Œå·¥å…·è°ƒç”¨
    2. çŠ¶æ€æœºå¾ªç¯ï¼šåœ¨ Editor å’Œå·¥ä½œæµä¹‹é—´åˆ‡æ¢
    3. ç”¨æˆ·å¹²é¢„ç‚¹ï¼šæš‚åœå·¥ä½œæµç­‰å¾…ç”¨æˆ·è¾“å…¥
    
    æ¨¡å¼ï¼š
    - EDITOR_MODEï¼šç¼–è¾‘å™¨æ¨¡å¼ï¼Œå¤„ç†ç”¨æˆ·å¯¹è¯
    - WORKFLOW_MODEï¼šå·¥ä½œæµæ¨¡å¼ï¼Œæ‰§è¡Œå‰§æœ¬ç”Ÿæˆ
    """
    
    MODE_EDITOR = "editor"
    MODE_WORKFLOW = "workflow"
    
    def __init__(
        self,
        llm_service: Any,
        retrieval_service: Any,
        parser_service: Any,
        summarization_service: Any,
        workspace_id: str,
        enable_checkpointer: bool = True
    ):
        """
        åˆå§‹åŒ–äº¤äº’å¼å·¥ä½œæµç¼–æ’å™¨
        
        Args:
            llm_service: LLM æœåŠ¡å®ä¾‹
            retrieval_service: æ£€ç´¢æœåŠ¡å®ä¾‹
            parser_service: è§£ææœåŠ¡å®ä¾‹
            summarization_service: æ‘˜è¦æœåŠ¡å®ä¾‹
            workspace_id: å·¥ä½œç©ºé—´ ID
            enable_checkpointer: æ˜¯å¦å¯ç”¨çŠ¶æ€æŒä¹…åŒ–
        """
        self.llm_service = llm_service
        self.retrieval_service = retrieval_service
        self.parser_service = parser_service
        self.summarization_service = summarization_service
        self.workspace_id = workspace_id
        
        self.node_factory = NodeFactory(
            llm_service=llm_service,
            retrieval_service=retrieval_service,
            parser_service=parser_service,
            summarization_service=summarization_service,
            workspace_id=workspace_id
        )
        
        super().__init__(self.node_factory)
        
        self.tool_executor = ToolExecutor(
            llm_service=llm_service,
            retrieval_service=retrieval_service,
            node_factory=self.node_factory,
            workspace_id=workspace_id
        )
        
        self.tool_service = ToolService(
            llm_service=llm_service,
            tool_executor=self.tool_executor,
            max_iterations=10
        )
        
        self.editor_agent = EditorAgent(tool_service=self.tool_service)
        
        self.graph = self._build_graph()
        
        checkpointer = MemorySaver() if enable_checkpointer else None
        self.config = {"checkpointer": checkpointer} if checkpointer else None
        
        logger.info("InteractiveWorkflowOrchestrator åˆå§‹åŒ–å®Œæˆ")
    
    def _build_graph(self):
        """æ„å»º LangGraph çŠ¶æ€å›¾"""
        workflow = StateGraph(GlobalState)
        
        workflow.add_node("planner", self._planner_node)
        workflow.add_node("navigator", self._navigator_node)
        workflow.add_node("director", self._director_node)
        workflow.add_node("retry_protection", self._retry_protection_node)
        workflow.add_node("writer", self._writer_node)
        workflow.add_node("fact_checker", self._fact_checker_node)
        workflow.add_node("step_advancer", self._step_advancer_node)
        workflow.add_node("compiler", self._compiler_node)
        workflow.add_node("editor", self._editor_node)
        
        workflow.set_entry_point("planner")
        
        workflow.add_edge("planner", "navigator")
        workflow.add_edge("navigator", "director")
        
        workflow.add_conditional_edges(
            "director",
            self._route_director_decision,
            {
                "pivot": "navigator",
                "navigate": "navigator",
                "write": "retry_protection",
                "editor": "editor"
            }
        )
        
        workflow.add_edge("retry_protection", "writer")
        workflow.add_edge("writer", "fact_checker")
        
        workflow.add_conditional_edges(
            "fact_checker",
            self._route_fact_check,
            {"invalid": "retry_protection", "valid": "step_advancer"}
        )
        
        workflow.add_conditional_edges(
            "step_advancer",
            self._route_completion,
            {"continue": "navigator", "done": "editor"}
        )
        
        workflow.add_conditional_edges(
            "editor",
            self._route_editor_decision,
            {
                "continue_workflow": "navigator",
                "stay_in_editor": "editor",
                "finish": "compiler"
            }
        )
        
        workflow.add_edge("compiler", END)
        
        return workflow.compile()
    
    def _route_director_decision(self, state: GlobalState) -> str:
        """è·¯ç”±å¯¼æ¼”å†³ç­–"""
        director_feedback = self._get_state_value(state, "director_feedback", {})
        decision = director_feedback.get("decision", "write")
        
        if decision == "editor":
            return "editor"
        elif decision == "continue":
            return "write"
        return decision
    
    def _route_fact_check(self, state: GlobalState) -> str:
        """è·¯ç”±äº‹å®æ£€æŸ¥ç»“æœ"""
        fact_check_passed = self._get_state_value(state, "fact_check_passed", False)
        return "valid" if fact_check_passed else "invalid"
    
    def _route_completion(self, state: GlobalState) -> str:
        """è·¯ç”±å®ŒæˆçŠ¶æ€"""
        outline = self._get_state_value(state, "outline", [])
        current_step_index = self._get_state_value(state, "current_step_index", 0)
        
        if current_step_index >= len(outline):
            return "done"
        return "continue"
    
    def _route_editor_decision(self, state: GlobalState) -> str:
        """è·¯ç”±ç¼–è¾‘å™¨å†³ç­–"""
        awaiting_user_input = self._get_state_value(state, "awaiting_user_input", False)
        
        if awaiting_user_input:
            return "stay_in_editor"
        
        user_intervention = self._get_state_value(state, "human_intervention", None)
        
        if user_intervention and user_intervention.get("completed_at") is None:
            return "stay_in_editor"
        
        outline = self._get_state_value(state, "outline", [])
        current_step_index = self._get_state_value(state, "current_step_index", 0)
        
        if current_step_index >= len(outline):
            return "finish"
        
        return "continue_workflow"
    
    async def _editor_node(self, state: GlobalState) -> Dict[str, Any]:
        """ç¼–è¾‘å™¨èŠ‚ç‚¹ - å¤„ç†ç”¨æˆ·è¾“å…¥å’Œå·¥å…·è°ƒç”¨"""
        user_message = self._get_state_value(state, "user_message", "")
        chat_history = self._get_state_value(state, "chat_history", [])
        
        if not user_message:
            return {
                "awaiting_user_input": True,
                "editor_response": "è¯·è¾“å…¥æ‚¨æƒ³è¦æ‰§è¡Œçš„ä¿®æ”¹æˆ–æ“ä½œã€‚"
            }
        
        result = await self.editor_agent.process_message(
            user_message=user_message,
            state=state,
            chat_history=chat_history,
            include_context=True
        )
        
        return {
            "editor_response": result["response"],
            "chat_history": result["updated_chat_history"],
            "awaiting_user_input": result["requires_user_input"],
            "human_intervention": state.get("human_intervention"),
            "exceeded_max_iterations": result.get("exceeded_max_iterations", False)
        }
    
    async def execute_workflow(
        self,
        initial_state: GlobalState,
        user_inputs: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥ä½œæµ
        
        Args:
            initial_state: åˆå§‹çŠ¶æ€
            user_inputs: å¯é€‰çš„ç”¨æˆ·è¾“å…¥åˆ—è¡¨
            
        Returns:
            æœ€ç»ˆçŠ¶æ€
        """
        state = initial_state.copy()
        
        if user_inputs:
            state["user_inputs"] = user_inputs
            state["current_input_index"] = 0
        
        final_state = None
        
        async for chunk in self.graph.astream(state, config=self.config):
            for node_name, node_output in chunk.items():
                logger.info(f"Node {node_name} completed")
                
                if node_name == "editor" and "editor_response" in node_output:
                    response = node_output["editor_response"]
                    print(f"\nğŸ¤– Editor: {response}")
                    
                    if node_output.get("awaiting_user_input"):
                        continue
                
                if node_name == "compiler" and "final_script" in node_output:
                    final_state = {**state, **node_output}
                    print(f"\nâœ… å‰§æœ¬ç”Ÿæˆå®Œæˆï¼")
                    print(f"ğŸ“„ è„šæœ¬é•¿åº¦: {len(node_output['final_script'])} å­—ç¬¦")
        
        return final_state or state
    
    async def process_user_message(
        self,
        state: GlobalState,
        user_message: str
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            state: å½“å‰çŠ¶æ€
            user_message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        state["user_message"] = user_message
        
        async for chunk in self.graph.astream(state, config=self.config):
            for node_name, node_output in chunk.items():
                if node_name == "editor":
                    return {**state, **node_output}
        
        return state
