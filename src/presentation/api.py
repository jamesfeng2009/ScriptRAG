"""ç²¾ç®€ç‰ˆ REST API - ä¸“æ³¨äº RAG å‰§æœ¬ç”Ÿæˆ"""

import logging
import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime
from enum import Enum

from fastapi import FastAPI, HTTPException, BackgroundTasks, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from ..config import get_app_config, get_llm_config
from ..domain.state_types import GlobalState
from ..application.orchestrator import WorkflowOrchestrator
from ..services.llm.service import LLMService
from ..services.retrieval_service import RetrievalService, RetrievalConfig
from ..infrastructure.logging import configure_logging
from ..services.persistence.task_persistence_service import TaskDatabaseService, TaskRecord, TaskService


logger = logging.getLogger(__name__)


class TaskStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


class SkillType(str, Enum):
    STANDARD_TUTORIAL = "standard_tutorial"
    WARNING_MODE = "warning_mode"
    VISUALIZATION_ANALOGY = "visualization_analogy"
    RESEARCH_MODE = "research_mode"
    MEME_STYLE = "meme_style"


class RAGConfig(BaseModel):
    """RAGé…ç½®"""
    enable_hybrid_search: bool = True
    top_k: int = Field(5, ge=1, le=20)
    enable_reranking: bool = True


class SkillConfig(BaseModel):
    """Skillé…ç½®"""
    initial_skill: SkillType = SkillType.STANDARD_TUTORIAL
    enable_auto_switch: bool = True
    switch_threshold: float = Field(0.7, ge=0.0, le=1.0)


class GenerateRequest(BaseModel):
    """å‰§æœ¬ç”Ÿæˆè¯·æ±‚"""
    topic: str = Field(..., min_length=1, description="ç”Ÿæˆä¸»é¢˜")
    context: Optional[str] = Field("", description="ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯ç”¨äºä¼ å…¥å¯¹è¯å†å²ï¼‰")
    chat_session_id: Optional[str] = Field(None, description="å…³è”çš„ Chat Session IDï¼ˆå¯é€‰ï¼‰")
    rag: Optional[RAGConfig] = Field(default_factory=RAGConfig)
    rag_sources: Optional[List[str]] = Field(
        default=None,
        description="æŒ‡å®šæ–‡æ¡£åˆ†ç±»ï¼Œä¸ä¼ åˆ™æ£€ç´¢æ‰€æœ‰ï¼Œå¦‚ ['python_tutorial', 'api_docs']"
    )
    skill: Optional[SkillConfig] = Field(default_factory=SkillConfig)
    enable_dynamic_adjustment: bool = Field(True, description="å¯ç”¨åŠ¨æ€æ–¹å‘è°ƒæ•´")
    max_retries: int = Field(3, ge=1, le=10)
    recursion_limit: int = Field(100, ge=10, le=200)


class GenerateResponse(BaseModel):
    """å‰§æœ¬ç”Ÿæˆå“åº”"""
    task_id: str
    status: TaskStatus
    screenplay: Optional[str] = None
    outline: Optional[List[Dict[str, Any]]] = None
    skill_history: Optional[List[Dict[str, Any]]] = None
    direction_changes: Optional[List[Dict[str, Any]]] = None
    error: Optional[str] = None
    created_at: datetime


class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”"""
    status: str
    llm_available: bool


class AdjustRequest(BaseModel):
    """æ–¹å‘è°ƒæ•´è¯·æ±‚"""
    action: str = Field(..., description="è°ƒæ•´åŠ¨ä½œ: switch_skill, skip_step, add_step, abort")
    skill: Optional[str] = Field(None, description="ç›®æ ‡ Skillï¼ˆswitch_skill æ—¶å¿…å¡«ï¼‰")
    step_index: Optional[int] = Field(None, description="æ­¥éª¤ç´¢å¼•ï¼ˆskip_step æ—¶å¿…å¡«ï¼‰")
    new_step: Optional[str] = Field(None, description="æ–°æ­¥éª¤æè¿°ï¼ˆadd_step æ—¶å¿…å¡«ï¼‰")
    reason: str = Field(..., description="è°ƒæ•´åŸå› ")


class AdjustResponse(BaseModel):
    """è°ƒæ•´å“åº”"""
    success: bool
    task_id: str
    action: str
    result: Dict[str, Any]
    message: str


class RAGAnalysisResponse(BaseModel):
    """RAGåˆ†æç»“æœå“åº”"""
    task_id: str
    has_analysis: bool
    content_types: Optional[List[str]] = None
    main_topic: Optional[str] = None
    sub_topics: Optional[List[str]] = None
    difficulty_level: Optional[float] = None
    tone_style: Optional[str] = None
    key_concepts: Optional[List[str]] = None
    warnings: Optional[List[str]] = None
    prerequisites: Optional[List[str]] = None
    suggested_skill: Optional[str] = None
    confidence: Optional[float] = None
    direction_changes: Optional[List[Dict[str, Any]]] = None
    skill_history: Optional[List[Dict[str, Any]]] = None
    analyzed_at: Optional[datetime] = None


class RAGAdjustRequest(BaseModel):
    """RAGåŠ¨æ€è°ƒæ•´è¯·æ±‚"""
    top_k: Optional[int] = Field(None, ge=1, le=20, description="æ£€ç´¢æ–‡æ¡£æ•°é‡")
    similarity_threshold: Optional[float] = Field(None, ge=0.0, le=1.0, description="ç›¸ä¼¼åº¦é˜ˆå€¼")
    enable_hybrid_search: Optional[bool] = Field(None, description="å¯ç”¨æ··åˆæœç´¢")
    enable_reranking: Optional[bool] = Field(None, description="å¯ç”¨é‡æ’åº")
    force_reanalysis: bool = Field(False, description="å¼ºåˆ¶é‡æ–°åˆ†æ")
    query: Optional[str] = Field(None, description="é‡æ–°æ£€ç´¢çš„æŸ¥è¯¢è¯")


class RAGAdjustResponse(BaseModel):
    """RAGåŠ¨æ€è°ƒæ•´å“åº”"""
    success: bool
    task_id: str
    previous_config: Dict[str, Any]
    new_config: Dict[str, Any]
    retrieved_docs_count: int
    analysis_result: Optional[Dict[str, Any]] = None
    message: str


class SkillCreateRequest(BaseModel):
    """åˆ›å»ºæŠ€èƒ½è¯·æ±‚"""
    skill_name: str = Field(..., min_length=1, max_length=100, description="æŠ€èƒ½åç§°")
    description: str = Field(..., description="æŠ€èƒ½æè¿°")
    tone: str = Field(..., description="è¯­è°ƒé£æ ¼")
    compatible_with: List[str] = Field(default_factory=list, description="å…¼å®¹çš„æŠ€èƒ½åˆ—è¡¨")
    prompt_config: Dict[str, Any] = Field(default_factory=dict, description="æç¤ºé…ç½®")
    is_enabled: bool = Field(True, description="æ˜¯å¦å¯ç”¨")
    is_default: bool = Field(False, description="æ˜¯å¦ä¸ºé»˜è®¤æŠ€èƒ½")


class SkillResponse(BaseModel):
    """æŠ€èƒ½å“åº”"""
    skill_name: str
    description: str
    tone: str
    compatible_with: List[str]
    prompt_config: Optional[Dict[str, Any]] = None
    is_enabled: bool
    is_default: bool
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None


class WorkspaceSkillsResponse(BaseModel):
    """æŠ€èƒ½åˆ—è¡¨å“åº”"""
    skills: List[SkillResponse]
    default_skill: Optional[str] = None
    total_count: int


class DocumentUploadRequest(BaseModel):
    """æ–‡æ¡£ä¸Šä¼ è¯·æ±‚"""
    title: str = Field(..., description="æ–‡æ¡£æ ‡é¢˜")
    file_name: str = Field(..., description="æ–‡ä»¶å")
    content: str = Field(..., description="æ–‡æ¡£å†…å®¹")
    category: Optional[str] = Field(None, description="æ–‡æ¡£åˆ†ç±»")
    metadata: Optional[Dict[str, Any]] = Field(None, description="å…ƒæ•°æ®")


class DocumentResponse(BaseModel):
    """æ–‡æ¡£å“åº”"""
    id: str
    title: str
    file_name: str
    category: Optional[str]
    file_size: int
    created_at: Optional[str]


class DocumentListResponse(BaseModel):
    """æ–‡æ¡£åˆ—è¡¨å“åº”"""
    documents: List[DocumentResponse]
    total_count: int
    page: int
    page_size: int


class DocumentSearchResponse(BaseModel):
    """æ–‡æ¡£æœç´¢å“åº”"""
    documents: List[Dict[str, Any]]
    total_count: int


class DocumentDeleteResponse(BaseModel):
    """æ–‡æ¡£åˆ é™¤å“åº”"""
    success: bool
    id: str


class IngestRequest(BaseModel):
    """æ–‡æ¡£æ‘„å…¥è¯·æ±‚"""
    file_path: str = Field(..., description="æ–‡ä»¶è·¯å¾„")
    source_id: Optional[str] = Field(None, description="æ–‡æ¡£å”¯ä¸€æ ‡è¯†")


class IngestResponse(BaseModel):
    """æ–‡æ¡£æ‘„å…¥å“åº”"""
    status: str
    source_id: str
    chunk_count: int
    error_msg: Optional[str] = None


class QueryRequest(BaseModel):
    """é—®ç­”æŸ¥è¯¢è¯·æ±‚"""
    question: str = Field(..., min_length=1, description="ç”¨æˆ·é—®é¢˜")
    history: Optional[List[Dict[str, str]]] = Field(None, description="å¯¹è¯å†å²")


class QueryResponse(BaseModel):
    """é—®ç­”æŸ¥è¯¢å“åº”"""
    answer: str
    sources: List[Dict[str, Any]]


task_store: Dict[str, Dict[str, Any]] = {}
task_service: Optional[TaskService] = None
skill_service: Optional[Any] = None
app_config = None
llm_service = None
retrieval_service = None
orchestrator: Optional[WorkflowOrchestrator] = None
document_service = None
chat_session_service: Optional[Any] = None
rag_service: Optional[Any] = None

DEFAULT_WORKSPACE = ""

app = FastAPI(
    title="RAG Screenplay Generator",
    description="å¸¦RAGå’ŒåŠ¨æ€æ–¹å‘è°ƒæ•´çš„å‰§æœ¬ç”Ÿæˆç³»ç»Ÿ",
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def init_services():
    """åˆå§‹åŒ–æœåŠ¡"""
    global app_config, llm_service, retrieval_service, orchestrator, task_service, skill_service, chat_session_service, summarization_service
    
    logger.info("Initializing services...")
    
    from dotenv import load_dotenv
    load_dotenv()
    
    app_config = get_app_config()
    configure_logging(level=app_config.log_level)
    
    import yaml
    config_path = app_config.config_path
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        logger.info(f"Configuration loaded from {config_path}")
    except Exception as e:
        logger.error(f"Failed to load configuration: {e}")
        config_data = {}
    
    llm_config = get_llm_config()
    llm_providers = config_data.get("llm", {}).setdefault("providers", {})
    
    if llm_config.glm_api_key:
        llm_providers.setdefault("glm", {})["api_key"] = llm_config.glm_api_key
        llm_providers.setdefault("glm", {})["base_url"] = "https://open.bigmodel.cn/api/paas/v4"
        logger.info("GLM API key loaded")
    
    if llm_config.openai_api_key:
        llm_providers.setdefault("openai", {})["api_key"] = llm_config.openai_api_key
        logger.info("OpenAI API key loaded")
    
    if llm_config.qwen_api_key:
        llm_providers.setdefault("qwen", {})["api_key"] = llm_config.qwen_api_key
        logger.info("QWEN API key loaded")
    
    try:
        llm_service = LLMService(config_data.get('llm', {}))
        logger.info("LLM service initialized")
    except Exception as e:
        logger.error(f"Failed to initialize LLM service: {e}")
        llm_service = None
    
    try:
        from ..services.chat_session_persistence_service import ChatSessionPersistenceService
        chat_session_service = ChatSessionPersistenceService.get_instance()
        logger.info("Chat session service initialized")
    except Exception as e:
        logger.error(f"Failed to initialize chat session service: {e}")
        chat_session_service = None
    
    try:
        db_service = TaskDatabaseService.create_from_env()
        task_service = TaskService(db_service, enable_cache=True)
        logger.info("Task service initialized with database persistence")
    except Exception as e:
        logger.error(f"Failed to initialize task service: {e}")
        task_service = None

    try:
        from ..services.skill_persistence_service import SkillDatabaseService, SkillService
        skill_db_service = SkillDatabaseService.create_from_env()
        skill_service = SkillService(skill_db_service, enable_cache=True)
        logger.info("Skill service initialized")
    except Exception as e:
        logger.error(f"Failed to initialize skill service: {e}")
        skill_service = None
    
    try:
        from ..services.database.vector_db import PostgresVectorDBService
        from ..config import get_database_config
        db_config = get_database_config()
        vector_db_service = PostgresVectorDBService(
            host=db_config.host,
            port=db_config.port,
            database=db_config.database,
            user=db_config.user,
            password=db_config.password
        )
        
        retrieval_config = RetrievalConfig(**config_data.get('retrieval', {}))
        retrieval_service = RetrievalService(
            vector_db_service=vector_db_service,
            llm_service=llm_service,
            config=retrieval_config
        )
        logger.info("Retrieval service initialized")
    except Exception as e:
        logger.error(f"Failed to initialize retrieval service: {e}")
        retrieval_service = None
    
    try:
        from ..services.summarization_service import SummarizationService
        summarization_service = SummarizationService(llm_service)
        logger.info("Summarization service initialized")
    except Exception as e:
        logger.error(f"Failed to initialize summarization service: {e}")
        summarization_service = None
    
    try:
        from ..services.document_persistence_service import DocumentService
        document_service = DocumentService()
        logger.info("Document service initialized")
    except Exception as e:
        logger.error(f"Failed to initialize document service: {e}")
        document_service = None
    
    logger.info("All services initialized")


@app.on_event("startup")
async def startup_event():
    init_services()


@app.on_event("shutdown")
async def shutdown_event():
    if task_service:
        await task_service.close()
    if document_service:
        await document_service.close()


@app.get("/", response_model=Dict[str, str])
async def root():
    return {"message": "RAG Screenplay Generator API v2.0", "docs": "/docs"}


@app.get("/health", response_model=HealthResponse)
async def health():
    return HealthResponse(
        status="healthy" if llm_service else "degraded",
        llm_available=llm_service is not None
    )


@app.post("/generate", response_model=GenerateResponse)
async def generate(request: GenerateRequest, background_tasks: BackgroundTasks):
    """ç”Ÿæˆå‰§æœ¬ï¼ˆæ ¸å¿ƒæ¥å£ï¼‰"""
    task_id = str(uuid.uuid4())
    
    logger.info(f"[GENERATE] ============================================")
    logger.info(f"[GENERATE] æ–°å»ºå‰§æœ¬ç”Ÿæˆä»»åŠ¡")
    logger.info(f"[GENERATE] task_id: {task_id}")
    logger.info(f"[GENERATE] topic: {request.topic[:100]}...")
    logger.info(f"[GENERATE] chat_session_id: {request.chat_session_id}")
    
    if request.skill:
        logger.info(f"[GENERATE] skill_config: initial_skill={request.skill.initial_skill}, auto_switch={request.skill.enable_auto_switch}, threshold={request.skill.switch_threshold}")
    else:
        logger.info(f"[GENERATE] skill_config: None (ä½¿ç”¨é»˜è®¤å€¼)")
    
    if not llm_service:
        logger.error("[GENERATE] LLM service ä¸å¯ç”¨")
        raise HTTPException(status_code=503, detail="LLM service not available")
    
    if not task_service:
        logger.error("[GENERATE] Task service ä¸å¯ç”¨")
        raise HTTPException(status_code=503, detail="Task service not available")
    
    skill_name = request.skill.initial_skill.value if request.skill else "standard_tutorial"
    
    task_record = TaskRecord(
        task_id=task_id,
        status=TaskStatus.PENDING.value,
        topic=request.topic,
        context=request.context,
        current_skill=skill_name,
        request_data=request.model_dump(),
        chat_session_id=request.chat_session_id
    )
    
    logger.info(f"[GENERATE] æ­£åœ¨åˆ›å»º Task è®°å½•...")
    await task_service.create(task_record)
    logger.info(f"[GENERATE] âœ… Task è®°å½•å·²åˆ›å»º: {task_id}")
    
    background_tasks.add_task(
        run_generation,
        task_id,
        request.model_dump()
    )
    
    logger.info(f"[GENERATE] åå°ä»»åŠ¡å·²å¯åŠ¨: task_id={task_id}")
    logger.info(f"[GENERATE] ============================================")
    
    return GenerateResponse(
        task_id=task_id,
        status=TaskStatus.PENDING,
        created_at=datetime.now()
    )


async def run_generation(task_id: str, request_data: Dict[str, Any]):
    """åå°æ‰§è¡Œå‰§æœ¬ç”Ÿæˆ"""
    logger.info(f"[RUN_GENERATION] ============================================")
    logger.info(f"[RUN_GENERATION] å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id}")
    logger.info(f"[RUN_GENERATION] request_data keys: {list(request_data.keys())}")
    
    user_topic = request_data.get("topic", "")
    if not user_topic:
        logger.warning(f"[RUN_GENERATION] topic ä¸ºç©ºï¼Œå°è¯•ä» context æˆ–å…¶ä»–å­—æ®µè·å–")
        user_topic = request_data.get("context", "") or "é»˜è®¤ä¸»é¢˜"
    logger.info(f"[RUN_GENERATION] user_topic: '{user_topic}' (length: {len(user_topic)})")
    
    if not task_service:
        logger.error(f"[RUN_GENERATION] Task service ä¸å¯ç”¨: {task_id}")
        return
    
    await task_service.update(task_id, status=TaskStatus.RUNNING.value)
    logger.info(f"[RUN_GENERATION] Task çŠ¶æ€æ›´æ–°ä¸º RUNNING: {task_id}")
    
    try:
        chat_session_id = request_data.get("chat_session_id")
        project_context = request_data.get("context", "")
        
        logger.info(f"[RUN_GENERATION] chat_session_id: {chat_session_id}")
        
        if chat_session_id:
            try:
                from ..services.chat_session_persistence_service import ChatSessionPersistenceService
                chat_service = ChatSessionPersistenceService.get_instance()
                await chat_service.connect()
                chat_session = await chat_service.get(chat_session_id)
                
                if chat_session and chat_session.message_history:
                    history_text = "\n\n".join([
                        f"ã€{msg['role']}ã€‘\n{msg['content']}"
                        for msg in chat_session.message_history
                    ])
                    project_context = f"[å¯¹è¯å†å²]\n{history_text}\n\n[ç”Ÿæˆè¦æ±‚]\n{project_context}"
                    logger.info(f"[RUN_GENERATION] å·²åŠ è½½å¯¹è¯å†å², message_count={len(chat_session.message_history)}")
                else:
                    logger.info(f"[RUN_GENERATION] å¯¹è¯å†å²ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            except Exception as e:
                logger.warning(f"[RUN_GENERATION] åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")
        
        skill = request_data.get("skill", {})
        if isinstance(skill, dict):
            initial_skill = skill.get("initial_skill", "standard_tutorial")
            enable_auto_switch = skill.get("enable_auto_switch", False)
            switch_threshold = skill.get("switch_threshold", 0.7)
        else:
            initial_skill = str(skill) if skill else "standard_tutorial"
            enable_auto_switch = False
            switch_threshold = 0.7
        
        logger.info(f"[RUN_GENERATION] æŠ€èƒ½é…ç½®: initial_skill={initial_skill}, auto_switch={enable_auto_switch}, threshold={switch_threshold}")
        
        rag_sources = request_data.get("rag_sources")
        if rag_sources:
            project_context = f"[ä½¿ç”¨æ–‡æ¡£åˆ†ç±»: {', '.join(rag_sources)}]\n{project_context}"
            logger.info(f"[RUN_GENERATION] RAG æº: {rag_sources}")
        
        user_topic = request_data.get("topic", "")
        logger.info(f"[RUN_GENERATION] user_topic: '{user_topic}' (length: {len(user_topic)})")
        
        state: GlobalState = {
            "user_topic": user_topic,
            "project_context": project_context,
            "current_skill": initial_skill,
            "skill_history": [],
            "outline": [],
            "current_step_index": 0,
            "fragments": [],
            "execution_log": [],
            "retrieved_docs": [],
            "director_feedback": None,
            "fact_check_passed": True,
            "error_flag": None,
            "retry_count": 0,
            "workflow_complete": False,
            "pivot_triggered": False,
            "pivot_reason": None,
            "final_screenplay": None,
            "task_stack": None,
        }
        
        if llm_service:
            llm_service.session_id = task_id
            logger.info(f"[RUN_GENERATION] LLM service session_id å·²è®¾ç½®: {task_id}")
        
        logger.info(f"[RUN_GENERATION] æ­£åœ¨åˆ›å»º WorkflowOrchestrator...")
        runtime_orchestrator = WorkflowOrchestrator(
            llm_service=llm_service,
            retrieval_service=retrieval_service,
            parser_service=None,
            summarization_service=summarization_service,
            workspace_id=DEFAULT_WORKSPACE,
            enable_dynamic_adjustment=request_data.get("enable_dynamic_adjustment", True)
        )
        
        logger.info(f"[RUN_GENERATE] å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        recursion_limit = request_data.get("recursion_limit", 100)
        result = await runtime_orchestrator.execute(state, recursion_limit=recursion_limit)
        logger.info(f"[RUN_GENERATION] å·¥ä½œæµæ‰§è¡Œå®Œæˆ: success={result['success']}")
        
        if result['success']:
            final_state = result['state']
            
            if isinstance(final_state, dict):
                execution_log = final_state.get("execution_log", [])
                skill_history = final_state.get("skill_history", [])
                outline_data = final_state.get("outline", [])
                screenplay = None
                for log in reversed(execution_log):
                    if log.get("action") == "final_screenplay":
                        screenplay = log.get("details", {}).get("screenplay")
                        logger.info(f"[RUN_GENERATION] å·²è·å–æœ€ç»ˆå‰§æœ¬, length={len(screenplay) if screenplay else 0}")
                    elif log.get("action") == "skill_switch":
                        logger.info(f"[RUN_GENERATION] ğŸ¯ æŠ€èƒ½åˆ‡æ¢: {log.get('details')}")
            else:
                execution_log = getattr(final_state, "execution_log", [])
                skill_history = getattr(final_state, "skill_history", [])
                outline_data = getattr(final_state, "outline", [])
                screenplay = None
                for log in reversed(execution_log):
                    if log.get("action") == "final_screenplay":
                        screenplay = log.get("details", {}).get("screenplay")
                        logger.info(f"[RUN_GENERATION] å·²è·å–æœ€ç»ˆå‰§æœ¬, length={len(screenplay) if screenplay else 0}")
                    elif log.get("action") == "skill_switch":
                        logger.info(f"[RUN_GENERATION] ğŸ¯ æŠ€èƒ½åˆ‡æ¢: {log.get('details')}")
            
            if skill_history:
                logger.info(f"[RUN_GENERATION] æŠ€èƒ½å†å²è®°å½•: {len(skill_history)} æ¬¡åˆ‡æ¢")
                for h in skill_history:
                    logger.info(f"  - {h.get('from_skill')} â†’ {h.get('to_skill')}: {h.get('reason')}")
            
            logger.info(f"[RUN_GENERATION] æ­£åœ¨æ›´æ–° Task è®°å½•...")
            
            outline = []
            if isinstance(outline_data, list):
                outline = [
                    {"step_id": s.get("step_id") if isinstance(s, dict) else getattr(s, "step_id", ""), 
                     "description": s.get("description") if isinstance(s, dict) else getattr(s, "description", ""), 
                     "status": s.get("status") if isinstance(s, dict) else getattr(s, "status", "")}
                    for s in outline_data
                ]
            
            await task_service.update(
                task_id,
                status=TaskStatus.COMPLETED.value,
                screenplay=screenplay,
                outline=outline,
                skill_history=skill_history,
                direction_changes=[
                    {
                        "reason": h.get("reason"),
                        "from_skill": h.get("from_skill"),
                        "to_skill": h.get("to_skill"),
                        "triggered_by": h.get("step_id", "system")
                    }
                    for h in skill_history
                ],
                chat_session_id=chat_session_id
            )
            logger.info(f"[RUN_GENERATION] âœ… Task å·²å®Œæˆ: {task_id}")
            
            if chat_session_id:
                try:
                    from ..services.chat_session_persistence_service import ChatSessionPersistenceService
                    chat_service = ChatSessionPersistenceService.get_instance()
                    await chat_service.link_task(chat_session_id, task_id)
                    logger.info(f"[RUN_GENERATION] âœ… Task å·²å…³è”åˆ° Session: {chat_session_id} â†’ {task_id}")
                except Exception as e:
                    logger.warning(f"[RUN_GENERATION] å…³è” Task åˆ° Session å¤±è´¥: {e}")
        else:
            error_msg = result.get("error", "Unknown error")
            logger.error(f"[RUN_GENERATION] âŒ Task å¤±è´¥: {task_id}, error={error_msg}")
            await task_service.update(
                task_id,
                status=TaskStatus.FAILED.value,
                error=error_msg,
                chat_session_id=chat_session_id
            )
        
        logger.info(f"[RUN_GENERATION] ============================================")
    except Exception as e:
        logger.error(f"[RUN_GENERATION] âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {task_id}, error={e}")
        logger.exception("[RUN_GENERATION] è¯¦ç»†é”™è¯¯å †æ ˆ:")
        await task_service.update(
            task_id,
            status=TaskStatus.FAILED.value,
            error=str(e),
            chat_session_id=request_data.get("chat_session_id")
        )


@app.get("/result/{task_id}", response_model=GenerateResponse)
async def get_result(task_id: str):
    """è·å–ç”Ÿæˆç»“æœ"""
    if not task_service:
        raise HTTPException(status_code=503, detail="Task service not available")
    
    task = await task_service.get(task_id)
    
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    status = TaskStatus(task.status)
    
    response = GenerateResponse(
        task_id=task_id,
        status=status,
        created_at=task.created_at or datetime.now()
    )
    
    if status == TaskStatus.COMPLETED:
        response.screenplay = task.screenplay
        response.outline = task.outline
        response.skill_history = task.skill_history
        response.direction_changes = task.direction_changes
    elif status == TaskStatus.FAILED:
        response.error = task.error
    
    return response


@app.post("/adjust/{task_id}", response_model=AdjustResponse)
async def adjust_execution(
    task_id: str,
    request: AdjustRequest
):
    """åŠ¨æ€è°ƒæ•´æ‰§è¡Œæ–¹å‘"""
    if not task_service:
        raise HTTPException(status_code=503, detail="Task service not available")
    
    task = await task_service.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    if request.action not in ["switch_skill", "skip_step", "add_step", "abort"]:
        raise HTTPException(status_code=400, detail="Invalid action")
    
    if request.action == "switch_skill" and not request.skill:
        raise HTTPException(status_code=400, detail="Skill is required for switch_skill action")
    
    if task.status == TaskStatus.COMPLETED.value:
        raise HTTPException(status_code=400, detail="Cannot adjust a completed task")
    
    if task.status == TaskStatus.FAILED.value:
        raise HTTPException(status_code=400, detail="Cannot adjust a failed task")
    
    if request.action == "abort":
        await task_service.update(task_id, status=TaskStatus.FAILED.value, error="Aborted by user")
        return AdjustResponse(
            success=True,
            task_id=task_id,
            action=request.action,
            result={},
            message="Task aborted successfully"
        )
    
    return AdjustResponse(
        success=True,
        task_id=task_id,
        action=request.action,
        result={
            "skill": request.skill,
            "step_index": request.step_index,
            "new_step": request.new_step,
            "reason": request.reason
        },
        message=f"Adjustment '{request.action}' applied successfully"
    )


@app.get("/tasks/{task_id}/rag-analysis", response_model=RAGAnalysisResponse)
async def get_rag_analysis(task_id: str):
    """è·å– RAG åˆ†æç»“æœ"""
    if not task_service:
        raise HTTPException(status_code=503, detail="Task service not available")
    
    task = await task_service.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    return RAGAnalysisResponse(
        task_id=task_id,
        has_analysis=False,
        main_topic=task.topic,
        suggested_skill=task.current_skill,
        direction_changes=task.direction_changes,
        skill_history=task.skill_history
    )


@app.post("/tasks/{task_id}/rag-adjust", response_model=RAGAdjustResponse)
async def adjust_rag_config(
    task_id: str,
    request: RAGAdjustRequest
):
    """åŠ¨æ€è°ƒæ•´ RAG é…ç½®"""
    if not task_service:
        raise HTTPException(status_code=503, detail="Task service not available")
    
    task = await task_service.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    previous_config = {
        "top_k": request.top_k,
        "similarity_threshold": request.similarity_threshold,
        "enable_hybrid_search": request.enable_hybrid_search,
        "enable_reranking": request.enable_reranking
    }
    
    return RAGAdjustResponse(
        success=True,
        task_id=task_id,
        previous_config=previous_config,
        new_config=previous_config,
        retrieved_docs_count=0,
        message="RAG configuration adjusted successfully"
    )


@app.get("/skills", response_model=WorkspaceSkillsResponse)
async def list_skills():
    """åˆ—å‡ºæ‰€æœ‰æŠ€èƒ½"""
    if not skill_service:
        raise HTTPException(status_code=503, detail="Skill service not available")

    skills = await skill_service.get_all()
    default_skill = await skill_service.get_default()

    return WorkspaceSkillsResponse(
        skills=[
            SkillResponse(
                skill_name=s.skill_name,
                description=s.description,
                tone=s.tone,
                compatible_with=s.compatible_with,
                prompt_config=s.prompt_config,
                is_enabled=s.is_enabled,
                is_default=s.is_default,
                created_at=s.created_at,
                updated_at=s.updated_at
            )
            for s in skills
        ],
        default_skill=default_skill.skill_name if default_skill else None,
        total_count=len(skills)
    )


@app.post("/skills", response_model=SkillResponse)
async def create_skill(request: SkillCreateRequest):
    """åˆ›å»ºæ–°æŠ€èƒ½"""
    if not skill_service:
        raise HTTPException(status_code=503, detail="Skill service not available")

    from ..services.skill_persistence_service import SkillRecord

    existing = await skill_service.get(request.skill_name)
    if existing:
        raise HTTPException(status_code=409, detail=f"Skill '{request.skill_name}' already exists")

    record = SkillRecord(
        skill_name=request.skill_name,
        description=request.description,
        tone=request.tone,
        compatible_with=request.compatible_with,
        prompt_config=request.prompt_config,
        is_enabled=request.is_enabled,
        is_default=request.is_default
    )

    result = await skill_service.create(record)

    return SkillResponse(
        skill_name=result.skill_name,
        description=result.description,
        tone=result.tone,
        compatible_with=result.compatible_with,
        prompt_config=result.prompt_config,
        is_enabled=result.is_enabled,
        is_default=result.is_default,
        created_at=result.created_at,
        updated_at=result.updated_at
    )


@app.get("/skills/{skill_name}", response_model=SkillResponse)
async def get_skill(skill_name: str):
    """è·å–æŠ€èƒ½è¯¦æƒ…"""
    if not skill_service:
        raise HTTPException(status_code=503, detail="Skill service not available")

    skill = await skill_service.get(skill_name)
    if not skill:
        raise HTTPException(status_code=404, detail=f"Skill '{skill_name}' not found")

    return SkillResponse(
        skill_name=skill.skill_name,
        description=skill.description,
        tone=skill.tone,
        compatible_with=skill.compatible_with,
        prompt_config=skill.prompt_config,
        is_enabled=skill.is_enabled,
        is_default=skill.is_default,
        created_at=skill.created_at,
        updated_at=skill.updated_at
    )


@app.delete("/skills/{skill_name}")
async def delete_skill(skill_name: str):
    """åˆ é™¤æŠ€èƒ½"""
    if not skill_service:
        raise HTTPException(status_code=503, detail="Skill service not available")

    if not await skill_service.exists(skill_name):
        raise HTTPException(status_code=404, detail=f"Skill '{skill_name}' not found")

    await skill_service.delete(skill_name)

    return {"success": True, "skill_name": skill_name}


@app.post("/documents", response_model=DocumentResponse)
async def upload_document(request: DocumentUploadRequest):
    """ä¸Šä¼ æ–‡æ¡£"""
    if not document_service:
        raise HTTPException(status_code=503, detail="Document service not available")

    from ..services.document_persistence_service import DocumentRecord
    import hashlib

    content_hash = hashlib.md5(request.content.encode()).hexdigest()
    file_size = len(request.content.encode())

    record = DocumentRecord(
        id=str(uuid.uuid4()),
        title=request.title,
        file_name=request.file_name,
        content=request.content,
        content_hash=content_hash,
        file_size=file_size,
        category=request.category,
        metadata=request.metadata
    )

    result = await document_service.create(
        title=record.title,
        file_name=record.file_name,
        content=record.content,
        category=record.category,
        file_size=record.file_size,
        metadata=record.metadata
    )

    return DocumentResponse(
        id=str(result.id),
        title=result.title,
        file_name=result.file_name,
        category=result.category,
        file_size=result.file_size,
        created_at=result.created_at.isoformat() if result.created_at else None
    )


@app.get("/documents", response_model=DocumentListResponse)
async def list_documents(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    category: Optional[str] = Query(None)
):
    """åˆ—å‡ºæ–‡æ¡£"""
    if not document_service:
        raise HTTPException(status_code=503, detail="Document service not available")

    offset = (page - 1) * page_size

    docs, total = await document_service.list_all(
        page=page,
        page_size=page_size,
        category=category
    )

    return DocumentListResponse(
        documents=[
            DocumentResponse(
                id=str(doc.id),
                title=doc.title,
                file_name=doc.file_name,
                category=doc.category,
                file_size=doc.file_size,
                created_at=doc.created_at.isoformat() if doc.created_at else None
            )
            for doc in docs
        ],
        total_count=total,
        page=page,
        page_size=page_size
    )


@app.get("/documents/search", response_model=DocumentSearchResponse)
async def search_documents(
    query: str = Query(..., min_length=1),
    top_k: int = Query(5, ge=1, le=20)
):
    """æœç´¢æ–‡æ¡£"""
    if not document_service:
        raise HTTPException(status_code=503, detail="Document service not available")

    results = await document_service.search_by_content(
        query=query,
        top_k=top_k
    )

    return DocumentSearchResponse(
        documents=results,
        total_count=len(results)
    )


@app.delete("/documents/{doc_id}", response_model=DocumentDeleteResponse)
async def delete_document(doc_id: str):
    """åˆ é™¤æ–‡æ¡£"""
    if not document_service:
        raise HTTPException(status_code=503, detail="Document service not available")

    success = await document_service.delete(doc_id)

    if not success:
        raise HTTPException(status_code=404, detail="Document not found")

    return DocumentDeleteResponse(success=True, id=doc_id)


@app.post("/ingest", response_model=IngestResponse)
async def ingest_document(request: IngestRequest):
    """æ–‡æ¡£æ‘„å…¥ - ETL æµæ°´çº¿"""
    from ..services.rag.etl_service import create_etl_service

    try:
        etl_service = await create_etl_service(workspace_id=DEFAULT_WORKSPACE)
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"ETL service not available: {str(e)}")

    try:
        result = await etl_service.ingest(
            file_path=request.file_path,
            source_id=request.source_id
        )

        return IngestResponse(
            status=result.status,
            source_id=result.source_id,
            chunk_count=result.chunk_count,
            error_msg=result.error_msg
        )
    except Exception as e:
        logger.error(f"Ingest failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/query", response_model=QueryResponse)
async def query_document(request: QueryRequest):
    """é—®ç­”æŸ¥è¯¢ - RAG æµæ°´çº¿"""
    from ..services.rag.rag_service import create_rag_service

    try:
        rag_service = await create_rag_service(workspace_id=DEFAULT_WORKSPACE)
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"RAG service not available: {str(e)}")

    try:
        result = await rag_service.query(
            question=request.question,
            history=request.history
        )

        return QueryResponse(
            answer=result.answer,
            sources=result.sources
        )
    except Exception as e:
        logger.error(f"Query failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class ChatMessage(BaseModel):
    """èŠå¤©æ¶ˆæ¯"""
    role: str = Field(..., description="è§’è‰²: user, assistant, system")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    timestamp: Optional[datetime] = None


class ChatSessionConfig(BaseModel):
    """Chat ä¼šè¯é…ç½®"""
    skill: Optional[str] = Field(None, description="é»˜è®¤æŠ€èƒ½")
    enable_rag: bool = Field(False, description="æ˜¯å¦å¯ç”¨ RAG")
    rag_sources: Optional[List[str]] = Field(None, description="RAG æ–‡æ¡£åˆ†ç±»")
    system_prompt: Optional[str] = Field(None, description="è‡ªå®šä¹‰ system prompt")
    temperature: float = Field(0.7, ge=0.0, le=2.0)


class ChatSession(BaseModel):
    """Chat ä¼šè¯"""
    session_id: str
    mode: str = Field(..., description="simple æˆ– agent")
    config: ChatSessionConfig
    created_at: datetime
    message_count: int = 0


class CreateSessionRequest(BaseModel):
    """åˆ›å»ºä¼šè¯è¯·æ±‚"""
    mode: str = Field("agent", description="æ¨¡å¼: simple æˆ– agent")
    skill: Optional[str] = Field(None, description="é»˜è®¤æŠ€èƒ½")
    enable_rag: bool = Field(False, description="æ˜¯å¦å¯ç”¨ RAG")
    rag_sources: Optional[List[str]] = Field(None, description="RAG æ–‡æ¡£åˆ†ç±»")
    system_prompt: Optional[str] = Field(None, description="è‡ªå®šä¹‰ system prompt")
    temperature: float = Field(0.7, ge=0.0, le=2.0)


class CreateSessionResponse(BaseModel):
    """åˆ›å»ºä¼šè¯å“åº”"""
    session_id: str
    mode: str
    config: ChatSessionConfig
    created_at: datetime
    message_count: int = 0


class SendMessageRequest(BaseModel):
    """å‘é€æ¶ˆæ¯è¯·æ±‚"""
    message: str = Field(..., min_length=1, description="ç”¨æˆ·æ¶ˆæ¯")
    skill: Optional[str] = Field(None, description="ä¸´æ—¶è¦†ç›–é»˜è®¤æŠ€èƒ½")
    enable_rag: Optional[bool] = Field(None, description="ä¸´æ—¶è¦†ç›– RAG è®¾ç½®")


class SendMessageResponse(BaseModel):
    """å‘é€æ¶ˆæ¯å“åº”"""
    session_id: str
    role: str = "assistant"
    response: str
    skill_used: Optional[str] = None
    sources: Optional[List[str]] = None
    timestamp: datetime


class ChatHistoryManager:
    """å¯¹è¯å†å²ç®¡ç†å™¨"""
    
    _sessions: Dict[str, Dict[str, Any]] = {}
    _messages: Dict[str, List[ChatMessage]] = {}
    _session_timestamps: Dict[str, datetime] = {}
    MAX_HISTORY_LENGTH = 20
    
    @classmethod
    def create_session(cls, session_id: str, mode: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session = {
            "session_id": session_id,
            "mode": mode,
            "config": config,
            "created_at": datetime.now(),
            "message_count": 0
        }
        cls._sessions[session_id] = session
        cls._messages[session_id] = []
        cls._session_timestamps[session_id] = datetime.now()
        return session
    
    @classmethod
    def get_session(cls, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return cls._sessions.get(session_id)
    
    @classmethod
    def get_history(cls, session_id: str) -> List[ChatMessage]:
        """è·å–ä¼šè¯å†å²"""
        if session_id not in cls._messages:
            return []
        return cls._messages[session_id]
    
    @classmethod
    def add_message(cls, session_id: str, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯"""
        if session_id not in cls._messages:
            cls._messages[session_id] = []
        
        cls._messages[session_id].append(ChatMessage(
            role=role,
            content=content,
            timestamp=datetime.now()
        ))
        
        if session_id in cls._sessions:
            cls._sessions[session_id]["message_count"] += 1
        
        if len(cls._messages[session_id]) > cls.MAX_HISTORY_LENGTH:
            cls._messages[session_id] = cls._messages[session_id][-cls.MAX_HISTORY_LENGTH:]
    
    @classmethod
    def delete_session(cls, session_id: str):
        """åˆ é™¤ä¼šè¯"""
        if session_id in cls._sessions:
            del cls._sessions[session_id]
        if session_id in cls._messages:
            del cls._messages[session_id]
        if session_id in cls._session_timestamps:
            del cls._session_timestamps[session_id]
    
    @classmethod
    def list_sessions(cls) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
        return list(cls._sessions.values())


class SimpleChatRequest(BaseModel):
    """ç®€å• Chat è¯·æ±‚"""
    message: str = Field(..., min_length=1, description="ç”¨æˆ·æ¶ˆæ¯")
    skill: Optional[str] = Field(None, description="æŠ€èƒ½åç§°ï¼Œå¦‚ mysterious_fantasy, hot_battle")
    temperature: float = Field(0.7, ge=0.0, le=2.0, description="ç”Ÿæˆæ¸©åº¦")
    max_tokens: Optional[int] = Field(None, ge=1, le=10000, description="æœ€å¤§ç”Ÿæˆtokenæ•°")


class SimpleChatResponse(BaseModel):
    """ç®€å• Chat å“åº”"""
    session_id: str
    response: str
    skill_used: Optional[str] = None
    tokens_used: Optional[int] = None
    timestamp: datetime


class AgentChatRequest(BaseModel):
    """Agent Chat è¯·æ±‚"""
    session_id: Optional[str] = Field(None, description="ä¼šè¯IDï¼Œä¸ä¼ åˆ™åˆ›å»ºæ–°ä¼šè¯")
    message: str = Field(..., min_length=1, description="ç”¨æˆ·æ¶ˆæ¯")
    skill: Optional[str] = Field(None, description="æŠ€èƒ½åç§°")
    enable_rag: bool = Field(False, description="æ˜¯å¦å¯ç”¨ RAG")
    rag_sources: Optional[List[str]] = Field(None, description="RAG æ–‡æ¡£åˆ†ç±»")
    clear_history: bool = Field(False, description="æ˜¯å¦æ¸…ç©ºå†å²")


class AgentChatResponse(BaseModel):
    """Agent Chat å“åº”"""
    session_id: str
    response: str
    skill_used: Optional[str] = None
    sources: Optional[List[str]] = None
    timestamp: datetime


@app.post("/chat/simple", response_model=SimpleChatResponse)
async def simple_chat(request: SimpleChatRequest):
    """
    ç®€å• Chat æ¨¡å¼ - ç›´æ¥è°ƒç”¨ LLM
    
    ç‰¹ç‚¹ï¼š
    - å»¶è¿Ÿä½ã€æˆæœ¬ä½
    - é€‚åˆå¿«é€Ÿé—®ç­”
    - æŠ€èƒ½é€šè¿‡ System Prompt å½±å“è¾“å‡ºé£æ ¼
    """
    session_id = request.session_id if hasattr(request, 'session_id') and request.session_id else "simple_chat"
    
    ChatHistoryManager.add_message(session_id, "user", request.message)
    history = ChatHistoryManager.get_history(session_id)
    
    skill_prompt = ""
    if request.skill:
        if skill_service:
            skill_record = await skill_service.get(request.skill)
            if skill_record and skill_record.prompt_config:
                skill_prompt = skill_record.prompt_config.get("system_prompt", "")
    
    messages_for_llm = []
    if skill_prompt:
        messages_for_llm.append({"role": "system", "content": skill_prompt})
    
    for msg in history[-10:]:
        messages_for_llm.append({"role": msg.role, "content": msg.content})
    
    if not llm_service:
        raise HTTPException(status_code=503, detail="LLM service not available")
    
    try:
        response_text = await llm_service.chat_completion(
            messages=messages_for_llm,
            temperature=request.temperature,
            max_tokens=request.max_tokens or 2000
        )
        
        ChatHistoryManager.add_message(session_id, "assistant", response_text)
        
        return SimpleChatResponse(
            session_id=session_id,
            response=response_text,
            skill_used=request.skill,
            tokens_used=len(response_text) // 4,
            timestamp=datetime.now()
        )
    except Exception as e:
        logger.error(f"Simple chat failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chat/agent", response_model=AgentChatResponse)
async def agent_chat(request: AgentChatRequest):
    """
    Agent Chat æ¨¡å¼ - é€šè¿‡ Agent å·¥ä½œæµ
    
    ç‰¹ç‚¹ï¼š
    - æ”¯æŒå¤šè½®å¯¹è¯å†å²
    - æ”¯æŒåŠ¨æ€åˆ‡æ¢æŠ€èƒ½
    - æ”¯æŒ RAG çŸ¥è¯†æ£€ç´¢
    - é€‚åˆä¸“ä¸šå‰§æœ¬ç”Ÿæˆ
    """
    session_id = request.session_id or f"agent_{uuid.uuid4().hex[:8]}"
    
    if request.clear_history:
        ChatHistoryManager.clear_history(session_id)
    
    ChatHistoryManager.add_message(session_id, "user", request.message)
    history = ChatHistoryManager.get_history(session_id)
    
    context = ""
    if request.enable_rag and rag_service:
        try:
            rag_result = await rag_service.query(
                question=request.message,
                history=[{"role": m.role, "content": m.content} for m in history[-5:]]
            )
            context = rag_result.answer
        except Exception as e:
            logger.warning(f"RAG query failed: {e}")
    
    current_skill = request.skill or "standard_tutorial"
    if skill_service and request.skill:
        skill_record = await skill_service.get(request.skill)
        if skill_record:
            system_prompt = skill_record.prompt_config.get("system_prompt", "")
            if system_prompt:
                context = f"[å†™ä½œé£æ ¼: {request.skill}]\n{system_prompt}\n\n[å‚è€ƒçŸ¥è¯†]\n{context}" if context else f"[å†™ä½œé£æ ¼: {request.skill}]\n{system_prompt}"
    
    history_text = "\n".join([
        f"{msg.role}: {msg.content}" 
        for msg in history[-10:]
    ])
    
    full_prompt = f"""[å¯¹è¯å†å²]
{history_text}

[ç”¨æˆ·æ–°è¯·æ±‚]
{request.message}
"""
    
    if context:
        full_prompt = f"{context}\n\n{full_prompt}"
    
    if not llm_service:
        raise HTTPException(status_code=503, detail="LLM service not available")
    
    try:
        response_text = await llm_service.chat_completion(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰§æœ¬å†™ä½œåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.8,
            max_tokens=3000
        )
        
        ChatHistoryManager.add_message(session_id, "assistant", response_text)
        
        if chat_session_service:
            try:
                history = ChatHistoryManager.get_history(session_id)
                message_history = [
                    {"role": msg.role, "content": msg.content, "timestamp": msg.timestamp.isoformat()}
                    for msg in history
                ]
                await chat_session_service.update_message_history(session_id, message_history)
                logger.info(f"Message history persisted: {session_id}")
            except Exception as e:
                logger.error(f"Failed to persist message history: {e}")
        
        sources = None
        if request.enable_rag:
            sources = ["retrieved_knowledge"]
        
        return AgentChatResponse(
            session_id=session_id,
            response=response_text,
            skill_used=request.skill,
            sources=sources,
            timestamp=datetime.now()
        )
    except Exception as e:
        logger.error(f"Agent chat failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/chat/sessions", response_model=List[Dict[str, Any]])
async def list_chat_sessions():
    """åˆ—å‡ºæ‰€æœ‰ Chat ä¼šè¯"""
    return ChatHistoryManager.list_sessions()


@app.delete("/chat/sessions/{session_id}")
async def delete_chat_session(session_id: str):
    """åˆ é™¤ Chat ä¼šè¯"""
    ChatHistoryManager.delete_session(session_id)
    return {"success": True, "session_id": session_id}


@app.post("/chat/sessions", response_model=CreateSessionResponse)
async def create_chat_session(request: CreateSessionRequest):
    """
    åˆ›å»º Chat ä¼šè¯ï¼ˆå¸¦é…ç½®ï¼‰
    
    ç‰¹ç‚¹ï¼š
    - ä¸€æ¬¡æ€§é…ç½®ä¼šè¯å‚æ•°ï¼ˆskillã€ragã€temperatureï¼‰
    - åç»­æ¶ˆæ¯è‡ªåŠ¨ä½¿ç”¨è¿™äº›é…ç½®
    - æ”¯æŒéšæ—¶ä¿®æ”¹é»˜è®¤é…ç½®
    """
    session_id = f"chat_{uuid.uuid4().hex[:12]}"
    
    config = {
        "skill": request.skill,
        "enable_rag": request.enable_rag,
        "rag_sources": request.rag_sources,
        "system_prompt": request.system_prompt,
        "temperature": request.temperature
    }
    
    ChatHistoryManager.create_session(session_id, request.mode, config)
    
    if chat_session_service:
        try:
            from ..services.chat_session_persistence_service import ChatSessionRecord
            record = ChatSessionRecord(
                id=session_id,
                topic="",
                mode=request.mode,
                config=config,
                message_history=[],
                status="active"
            )
            await chat_session_service.create(record)
            logger.info(f"Chat session persisted: {session_id}")
        except Exception as e:
            logger.error(f"Failed to persist chat session: {e}")
    
    return CreateSessionResponse(
        session_id=session_id,
        mode=request.mode,
        config=ChatSessionConfig(**config),
        created_at=ChatHistoryManager.get_session(session_id)["created_at"],
        message_count=0
    )


@app.get("/chat/sessions/{session_id}", response_model=ChatSession)
async def get_chat_session(session_id: str):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    session = ChatHistoryManager.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    return ChatSession(
        session_id=session["session_id"],
        mode=session["mode"],
        config=ChatSessionConfig(**session["config"]),
        created_at=session["created_at"],
        message_count=session["message_count"]
    )


@app.get("/chat/sessions/{session_id}/messages", response_model=List[ChatMessage])
async def get_chat_messages(session_id: str):
    """è·å–ä¼šè¯æ¶ˆæ¯å†å²"""
    session = ChatHistoryManager.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    return ChatHistoryManager.get_history(session_id)


@app.post("/chat/sessions/{session_id}/messages", response_model=SendMessageResponse)
async def send_chat_message(
    session_id: str,
    request: SendMessageRequest
):
    """
    å‘é€æ¶ˆæ¯åˆ°ä¼šè¯
    
    ä½¿ç”¨ä¼šè¯é…ç½®çš„é»˜è®¤å‚æ•°ï¼Œä¹Ÿå¯ä¸´æ—¶è¦†ç›–
    """
    logger.info(f"[CHAT] æ”¶åˆ°æ¶ˆæ¯è¯·æ±‚: session_id={session_id}, message={request.message[:50]}...")
    
    session = ChatHistoryManager.get_session(session_id)
    if not session:
        logger.warning(f"[CHAT] Session ä¸å­˜åœ¨: {session_id}")
        raise HTTPException(status_code=404, detail="Session not found")
    
    config = session["config"]
    mode = session["mode"]
    
    logger.info(f"[CHAT] Session é…ç½®: mode={mode}, skill={config.get('skill')}, temperature={config.get('temperature')}")
    
    ChatHistoryManager.add_message(session_id, "user", request.message)
    logger.info(f"[CHAT] ç”¨æˆ·æ¶ˆæ¯å·²æ·»åŠ åˆ°å†…å­˜å†å²: role=user, content={request.message[:50]}...")
    
    if chat_session_service:
        try:
            history = ChatHistoryManager.get_history(session_id)
            message_history = [
                {"role": msg.role, "content": msg.content, "timestamp": msg.timestamp.isoformat()}
                for msg in history
            ]
            await chat_session_service.update_message_history(session_id, message_history)
            logger.info(f"[CHAT] âœ… ç”¨æˆ·æ¶ˆæ¯å·²æŒä¹…åŒ–åˆ°æ•°æ®åº“: session_id={session_id}")
        except Exception as e:
            logger.error(f"[CHAT] âŒ æŒä¹…åŒ–ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
    
    history = ChatHistoryManager.get_history(session_id)
    
    effective_skill = request.skill or config.get("skill")
    effective_rag = request.enable_rag if request.enable_rag is not None else config.get("enable_rag", False)
    
    logger.info(f"[CHAT] Effective parameters: skill={effective_skill}, rag={effective_rag}")
    
    context = ""
    if effective_rag and rag_service:
        try:
            rag_result = await rag_service.query(
                question=request.message,
                history=[{"role": m.role, "content": m.content} for m in history[-5:]]
            )
            context = rag_result.answer
            logger.info(f"[CHAT] RAG æŸ¥è¯¢æˆåŠŸ: context_length={len(context)}")
        except Exception as e:
            logger.warning(f"[CHAT] RAG æŸ¥è¯¢å¤±è´¥: {e}")
    
    if effective_skill and skill_service:
        skill_record = await skill_service.get(effective_skill)
        if skill_record and skill_record.prompt_config:
            system_prompt = skill_record.prompt_config.get("system_prompt", "")
            if system_prompt:
                context = f"[å†™ä½œé£æ ¼: {effective_skill}]\n{system_prompt}\n\n[å‚è€ƒçŸ¥è¯†]\n{context}" if context else f"[å†™ä½œé£æ ¼: {effective_skill}]\n{system_prompt}"
            logger.info(f"[CHAT] Skill é…ç½®å·²åº”ç”¨: skill={effective_skill}, prompt_length={len(system_prompt)}")
    
    if config.get("system_prompt"):
        context = f"{config['system_prompt']}\n\n{context}" if context else config["system_prompt"]
    
    history_text = "\n".join([
        f"{msg.role}: {msg.content}" 
        for msg in history[-10:]
    ])
    
    full_prompt = f"""[å¯¹è¯å†å²]
{history_text}

[ç”¨æˆ·æ–°è¯·æ±‚]
{request.message}
"""
    
    if context:
        full_prompt = f"{context}\n\n{full_prompt}"
    
    logger.info(f"[CHAT] å‡†å¤‡è°ƒç”¨ LLM: temperature={config.get('temperature', 0.7)}, max_tokens=3000, prompt_length={len(full_prompt)}")
    
    if not llm_service:
        logger.error("[CHAT] LLM service ä¸å¯ç”¨")
        raise HTTPException(status_code=503, detail="LLM service not available")
    
    try:
        response_text = await llm_service.chat_completion(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰§æœ¬å†™ä½œåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": full_prompt}
            ],
            temperature=config.get("temperature", 0.7),
            max_tokens=3000
        )
        logger.info(f"[CHAT] âœ… LLM è°ƒç”¨æˆåŠŸ: response_length={len(response_text)}")
        
        ChatHistoryManager.add_message(session_id, "assistant", response_text)
        logger.info(f"[CHAT] åŠ©æ‰‹æ¶ˆæ¯å·²æ·»åŠ åˆ°å†…å­˜å†å²")
        
        if chat_session_service:
            try:
                history = ChatHistoryManager.get_history(session_id)
                message_history = [
                    {"role": msg.role, "content": msg.content, "timestamp": msg.timestamp.isoformat()}
                    for msg in history
                ]
                await chat_session_service.update_message_history(session_id, message_history)
                logger.info(f"[CHAT] âœ… å®Œæ•´æ¶ˆæ¯å†å²å·²æŒä¹…åŒ–: message_count={len(message_history)}")
            except Exception as e:
                logger.error(f"[CHAT] âŒ æŒä¹…åŒ–å®Œæ•´æ¶ˆæ¯å†å²å¤±è´¥: {e}")
        
        sources = None
        if effective_rag:
            sources = ["retrieved_knowledge"]
        
        response = SendMessageResponse(
            session_id=session_id,
            response=response_text,
            skill_used=effective_skill,
            sources=sources,
            timestamp=datetime.now()
        )
        logger.info(f"[CHAT] âœ… å“åº”æ„å»ºæˆåŠŸ: skill_used={effective_skill}")
        return response
    except Exception as e:
        logger.error(f"[CHAT] âŒ LLM è°ƒç”¨æˆ–åç»­å¤„ç†å¤±è´¥: {e}")
        logger.exception("[CHAT] è¯¦ç»†é”™è¯¯:")
        raise HTTPException(status_code=500, detail=str(e))


class ChatExportResponse(BaseModel):
    """å¯¼å‡ºå¯¹è¯å†å²å“åº”"""
    session_id: str
    topic: Optional[str] = None
    mode: str
    message_count: int
    history_text: str
    created_at: Optional[datetime] = None


@app.get("/chat/sessions/{session_id}/export", response_model=ChatExportResponse)
async def export_chat_history(session_id: str):
    """
    å¯¼å‡ºå¯¹è¯å†å²ï¼ˆç”¨äºç”Ÿæˆå‰§æœ¬ï¼‰
    
    å°†å¯¹è¯å†å²è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼ï¼Œå¯ç›´æ¥ç”¨äºç”Ÿæˆå‰§æœ¬çš„ context
    """
    session = ChatHistoryManager.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    
    messages = ChatHistoryManager.get_history(session_id)
    
    history_text = "\n\n".join([
        f"ã€{msg.role}ã€‘\n{msg.content}"
        for msg in messages
    ])
    
    return ChatExportResponse(
        session_id=session_id,
        topic=session.get("config", {}).get("topic"),
        mode=session["mode"],
        message_count=len(messages),
        history_text=history_text or "(æš‚æ— å¯¹è¯)",
        created_at=session.get("created_at")
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "src.presentation.api:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
